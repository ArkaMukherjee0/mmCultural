{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4Sv4MxLtJ4gn"},"outputs":[],"source":["# prompt: mount google drive  folder named 'mmCultural'\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Navigate to the specific folder within your Google Drive\n","%cd /content/drive/My Drive/mmCultural"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ifb60HNLIc8"},"outputs":[],"source":["!pip install evaluate bert_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PxdVSPH-JKdn"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Starting VLM Cultural Competence Analysis...\n","This will compute Kendall's tau correlations between text similarities and cultural distances\n","Running in single response mode\n","\n","==================================================\n","ANALYZING WITH HOFSTEDE\n","==================================================\n","\n","Analyzing responses_gemma_3_4b_it.jsonl...\n","Loaded 2937 responses\n","Found 35 concepts: ['zoo', 'near a river', 'farm animals', 'kindness', 'robots', 'school', 'pets', 'space', 'compassion', 'humility', 'patience', 'fishes', 'sharing', 'ocean', 'library', 'respect', 'mythological figures', 'magicians', 'honesty', 'never hurting anyone', 'not being selfish', 'insects', 'friends', 'wild animals', 'forest', 'gratitude', 'not lying', 'birds', 'cooperation', 'playground', 'hard work', 'place of worship', 'empathy', 'farm', 'not being greedy']\n","Found 42 identities: ['Filipino', 'Tanzanian', 'Czech', 'Dutch', 'Indonesian', 'Indian', 'Egyptian', 'South Sudanese', 'German', 'Romanian', 'Mexican', 'Greek', 'Pakistani', 'Australian', 'Iraqi', 'Turkish', 'Zimbabwean', 'Polish', 'Israeli', 'Canadian', 'American', 'Kenyan', 'Ukrainian', 'Malaysian', 'Moroccan', 'Cameroonian', 'Bangladeshi', 'South African', 'Italian', 'Chinese', 'Belgian', 'Russian', 'French', 'Austrian', 'Nigerian', 'Thai', 'Ghanaian', 'Ugandan', 'Swedish', 'Spanish', 'British', 'Brazilian']\n","Computing pairwise similarities...\n","  Processing concept 'honesty' with identities: ['American', 'Indian', 'Nigerian', 'Pakistani', 'Indonesian', 'Filipino', 'British', 'German', 'Egyptian', 'Kenyan', 'French', 'Canadian', 'Australian', 'Ugandan', 'Polish', 'Ghanaian', 'Thai', 'Ukrainian', 'South African', 'Mexican', 'Malaysian', 'Dutch', 'Brazilian', 'Turkish', 'Zimbabwean', 'Iraqi', 'Bangladeshi', 'Spanish', 'South Sudanese', 'Chinese', 'Swedish', 'Italian', 'Tanzanian', 'Cameroonian', 'Moroccan', 'Belgian', 'Israeli', 'Austrian', 'Romanian', 'Greek', 'Czech', 'Russian']\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9456f1f0340049c7a1c1d24ef9c9d4b3","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1603843933724c608f81215a55d38999","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/482 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a3a97e913004a488503be53df5ece74","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6eadb7154ee4de7b80d7923c47f2fc4","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04acfd46a425492392b0ec5cbf972c59","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b397c98071ac4265968440b1fb086a04","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.42G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["    Similarity American-Indian: 0.8602\n","    Similarity American-Nigerian: 0.8607\n","    Similarity American-Pakistani: 0.8573\n","    Similarity American-Indonesian: 0.8413\n"]}],"source":["import json\n","import pandas as pd\n","import numpy as np\n","from scipy.stats import kendalltau\n","import sys\n","import os\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Add the cultural values folder to path\n","sys.path.append('./cultural_values')\n","import utils\n","\n","# File paths\n","INFERENCE_RESULTS_DIR = './inference_results'\n","CULTURAL_VALUES_DIR = './cultural_values'\n","\n","# Model files\n","MODEL_FILES = [\n","    'responses_gemma_3_4b_it.jsonl',\n","    'responses_gemma_3_12b_it_qat.jsonl',\n","    'responses_internvl3_8b.jsonl',\n","    'responses_qwen_qwen2.5_vl_7b.jsonl',\n","    'responses_smolvlm2_2.2b_instruct.jsonl'\n","]\n","\n","def load_jsonl_responses(file_path):\n","    \"\"\"Load responses from JSONL file\"\"\"\n","    responses = []\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            try:\n","                data = json.loads(line.strip())\n","                responses.append(data)\n","            except json.JSONDecodeError:\n","                continue\n","    return responses\n","\n","def convert_to_utils_format(responses, single_response_mode=True):\n","    \"\"\"\n","    Convert JSONL responses to the format expected by utils.compute_similarity\n","\n","    Expected format: data[topic][concept][identity][template] = [responses...]\n","\n","    Args:\n","        responses: List of response dictionaries from JSONL\n","        single_response_mode: If True, handles case where we only have 1 response per concept-identity pair\n","                             If False, expects multiple responses per concept-identity pair\n","    \"\"\"\n","    data = {}\n","\n","    for response in responses:\n","        concept = response['concept']\n","        identity = response['identity']\n","        model_response = response['response']\n","\n","        # Use concept as both topic and concept for compatibility\n","        topic = concept\n","\n","        if single_response_mode:\n","            # Create a generic template since we only have one response per identity-concept\n","            template = f\"story_about_{concept}\"\n","        else:\n","            # Use more specific template when we have multiple responses\n","            template = f\"Write about {concept} for {identity}\"\n","\n","        if topic not in data:\n","            data[topic] = {}\n","        if concept not in data[topic]:\n","            data[topic][concept] = {}\n","        if identity not in data[topic][concept]:\n","            data[topic][concept][identity] = {}\n","        if template not in data[topic][concept][identity]:\n","            data[topic][concept][identity][template] = []\n","\n","        data[topic][concept][identity][template].append(model_response.lower())\n","\n","    return data\n","\n","def compute_pairwise_similarities(data, metric='bertscore', single_response_mode=True):\n","    \"\"\"\n","    Compute pairwise similarities between identities for each concept\n","    Returns similarity matrix in the format expected by Kendall's tau analysis\n","\n","    Args:\n","        data: Response data in utils format\n","        metric: Similarity metric to use ('bertscore', 'bleu', 'wer')\n","        single_response_mode: If True, handles single response per identity-concept pair\n","    \"\"\"\n","    results = {}\n","\n","    for topic in data:\n","        results[topic] = {}\n","\n","        for concept in data[topic]:\n","            if concept == 'all_concepts':\n","                continue\n","\n","            identities = list(data[topic][concept].keys())\n","            results[topic][concept] = {}\n","\n","            print(f\"  Processing concept '{concept}' with identities: {identities}\")\n","\n","            # Check if we have enough data for meaningful comparison\n","            if len(identities) \u003c 2:\n","                print(f\"    Skipping {concept}: need at least 2 identities\")\n","                continue\n","\n","            # Initialize similarity matrix\n","            for identity1 in identities:\n","                results[topic][concept][identity1] = {}\n","                for identity2 in identities:\n","                    if identity1 == identity2:\n","                        results[topic][concept][identity1][identity2] = 1.0\n","                    elif identity1 in results[topic][concept] and identity2 in results[topic][concept][identity1]:\n","                        # Already computed (symmetric)\n","                        continue\n","                    else:\n","                        # Check if both identities have responses\n","                        if (identity1 not in data[topic][concept] or\n","                            identity2 not in data[topic][concept]):\n","                            print(f\"    Missing data for {identity1} or {identity2}\")\n","                            results[topic][concept][identity1][identity2] = 0.0\n","                            continue\n","\n","                        # In single response mode, we might not have common templates\n","                        # So we'll compare whatever responses we have\n","                        try:\n","                            similarity = utils.compute_similarity(\n","                                data[topic][concept][identity1],\n","                                data[topic][concept][identity2],\n","                                metric\n","                            )\n","\n","                            if similarity is not None and similarity != -1:\n","                                results[topic][concept][identity1][identity2] = similarity\n","                                # Ensure symmetry\n","                                if identity2 not in results[topic][concept]:\n","                                    results[topic][concept][identity2] = {}\n","                                results[topic][concept][identity2][identity1] = similarity\n","                                print(f\"    Similarity {identity1}-{identity2}: {similarity:.4f}\")\n","                            else:\n","                                # No common templates or comparison failed\n","                                print(f\"    No common templates for {identity1}-{identity2}\")\n","                                if single_response_mode:\n","                                    # In single response mode, use a different approach\n","                                    # We'll use simple text similarity instead\n","                                    similarity = compute_fallback_similarity(\n","                                        data[topic][concept][identity1],\n","                                        data[topic][concept][identity2]\n","                                    )\n","                                    results[topic][concept][identity1][identity2] = similarity\n","                                    if identity2 not in results[topic][concept]:\n","                                        results[topic][concept][identity2] = {}\n","                                    results[topic][concept][identity2][identity1] = similarity\n","                                    print(f\"    Fallback similarity {identity1}-{identity2}: {similarity:.4f}\")\n","                                else:\n","                                    results[topic][concept][identity1][identity2] = 0.0\n","                                    if identity2 not in results[topic][concept]:\n","                                        results[topic][concept][identity2] = {}\n","                                    results[topic][concept][identity2][identity1] = 0.0\n","\n","                        except Exception as e:\n","                            print(f\"    Error computing similarity for {identity1}-{identity2}: {e}\")\n","                            results[topic][concept][identity1][identity2] = 0.0\n","                            if identity2 not in results[topic][concept]:\n","                                results[topic][concept][identity2] = {}\n","                            results[topic][concept][identity2][identity1] = 0.0\n","\n","    return results\n","\n","def compute_fallback_similarity(responses1, responses2):\n","    \"\"\"\n","    Fallback similarity computation when we don't have common templates\n","    Uses simple sentence similarity between the first response from each identity\n","    \"\"\"\n","    try:\n","        # Get the first response from each identity\n","        resp1_templates = list(responses1.keys())\n","        resp2_templates = list(responses2.keys())\n","\n","        if not resp1_templates or not resp2_templates:\n","            return 0.0\n","\n","        resp1_text = responses1[resp1_templates[0]][0] if responses1[resp1_templates[0]] else \"\"\n","        resp2_text = responses2[resp2_templates[0]][0] if responses2[resp2_templates[0]] else \"\"\n","\n","        if not resp1_text or not resp2_text:\n","            return 0.0\n","\n","        # Use a simple approach: compute BLEU between the two responses\n","        # treating one as prediction and other as reference\n","        from nltk.translate.bleu_score import sentence_bleu\n","        from nltk.tokenize import word_tokenize\n","\n","        # Tokenize\n","        tokens1 = word_tokenize(resp1_text)\n","        tokens2 = word_tokenize(resp2_text)\n","\n","        if not tokens1 or not tokens2:\n","            return 0.0\n","\n","        # Compute BLEU in both directions and average\n","        bleu1 = sentence_bleu([tokens2], tokens1)\n","        bleu2 = sentence_bleu([tokens1], tokens2)\n","\n","        return (bleu1 + bleu2) / 2\n","\n","    except Exception as e:\n","        print(f\"      Fallback similarity computation failed: {e}\")\n","        return 0.0\n","\n","def load_cultural_distances(cultural_vectors_path, cultural_vectors_type):\n","    \"\"\"Load cultural distance matrices\"\"\"\n","    if 'hofstede' in cultural_vectors_type:\n","        return utils.get_hofstede_distances(cultural_vectors_path, cultural_vectors_type)\n","    elif 'wvs' in cultural_vectors_type:\n","        return utils.get_wvs_250_dims_distance(cultural_vectors_path, cultural_vectors_type)\n","    else:\n","        raise ValueError(f\"Unknown cultural vectors type: {cultural_vectors_type}\")\n","\n","def extract_similarity_matrix(similarity_results, concept):\n","    \"\"\"Extract similarity matrix for a specific concept\"\"\"\n","    # Find the topic that contains this concept\n","    topic_data = None\n","    for topic in similarity_results:\n","        if concept in similarity_results[topic]:\n","            topic_data = similarity_results[topic][concept]\n","            break\n","\n","    if topic_data is None:\n","        return None, None\n","\n","    identities = list(topic_data.keys())\n","    n = len(identities)\n","    matrix = np.zeros((n, n))\n","\n","    for i, id1 in enumerate(identities):\n","        for j, id2 in enumerate(identities):\n","            if id2 in topic_data[id1]:\n","                matrix[i, j] = topic_data[id1][id2]\n","            else:\n","                matrix[i, j] = 0.0\n","\n","    return matrix, identities\n","\n","def extract_cultural_matrix(cultural_distances, identities):\n","    \"\"\"Extract cultural distance matrix for given identities\"\"\"\n","    n = len(identities)\n","    matrix = np.zeros((n, n))\n","\n","    for i, id1 in enumerate(identities):\n","        for j, id2 in enumerate(identities):\n","            if id1 in cultural_distances and id2 in cultural_distances[id1]:\n","                matrix[i, j] = cultural_distances[id1][id2]\n","            else:\n","                matrix[i, j] = 0.0\n","\n","    return matrix\n","\n","def compute_kendalls_tau(similarity_matrix, cultural_matrix):\n","    \"\"\"Compute Kendall's tau between similarity and cultural distance matrices\"\"\"\n","    # Get upper triangular indices (excluding diagonal)\n","    n = similarity_matrix.shape[0]\n","    triu_indices = np.triu_indices(n, k=1)\n","\n","    sim_values = similarity_matrix[triu_indices]\n","    cultural_values = cultural_matrix[triu_indices]\n","\n","    # Remove any NaN or infinite values\n","    valid_mask = np.isfinite(sim_values) \u0026 np.isfinite(cultural_values)\n","    sim_values = sim_values[valid_mask]\n","    cultural_values = cultural_values[valid_mask]\n","\n","    if len(sim_values) \u003c 2:\n","        return None, None\n","\n","    tau, p_value = kendalltau(sim_values, cultural_values)\n","    return tau, p_value\n","\n","def analyze_model_correlations(model_file, cultural_vectors_path, cultural_vectors_type,\n","                             text_similarity_metric='bertscore', single_response_mode=True):\n","    \"\"\"Analyze correlations for a single model\"\"\"\n","    print(f\"\\nAnalyzing {model_file}...\")\n","\n","    # Load and process responses\n","    file_path = os.path.join(INFERENCE_RESULTS_DIR, model_file)\n","    responses = load_jsonl_responses(file_path)\n","    print(f\"Loaded {len(responses)} responses\")\n","\n","    # Check data structure\n","    concepts = set(r['concept'] for r in responses)\n","    identities = set(r['identity'] for r in responses)\n","    print(f\"Found {len(concepts)} concepts: {list(concepts)}\")\n","    print(f\"Found {len(identities)} identities: {list(identities)}\")\n","\n","    # Convert to utils format\n","    data = convert_to_utils_format(responses, single_response_mode=single_response_mode)\n","\n","    # Compute similarities\n","    print(\"Computing pairwise similarities...\")\n","    similarity_results = compute_pairwise_similarities(data, text_similarity_metric,\n","                                                     single_response_mode=single_response_mode)\n","\n","    # Load cultural distances\n","    print(\"Loading cultural distances...\")\n","    try:\n","        cultural_distances = load_cultural_distances(cultural_vectors_path, cultural_vectors_type)\n","    except Exception as e:\n","        print(f\"Error loading cultural distances: {e}\")\n","        return {}\n","\n","    # Analyze each concept\n","    results = {}\n","    concepts_list = [concept for topic in data for concept in data[topic] if concept != 'all_concepts']\n","\n","    for concept in concepts_list:\n","        print(f\"Analyzing concept: {concept}\")\n","\n","        # Extract matrices\n","        sim_matrix, identities_list = extract_similarity_matrix(similarity_results, concept)\n","        if sim_matrix is None:\n","            print(f\"  No similarity matrix for {concept}\")\n","            continue\n","\n","        # Check if we have enough identities for correlation\n","        if len(identities_list) \u003c 3:\n","            print(f\"  Not enough identities for {concept} (need at least 3, got {len(identities_list)})\")\n","            continue\n","\n","        cultural_matrix = extract_cultural_matrix(cultural_distances, identities_list)\n","\n","        # Check if cultural matrix has valid values\n","        cultural_flat = cultural_matrix[np.triu_indices(len(identities_list), k=1)]\n","        if np.all(cultural_flat == 0) or not np.any(np.isfinite(cultural_flat)):\n","            print(f\"  No valid cultural distances for identities: {identities_list}\")\n","            continue\n","\n","        # Compute Kendall's tau\n","        tau, p_value = compute_kendalls_tau(sim_matrix, cultural_matrix)\n","\n","        if tau is not None:\n","            results[concept] = {\n","                'tau': tau,\n","                'p_value': p_value,\n","                'identities': identities_list,\n","                'n_pairs': len(identities_list) * (len(identities_list) - 1) // 2\n","            }\n","            print(f\"  Tau: {tau:.4f}, p-value: {p_value:.4f} (n_pairs: {results[concept]['n_pairs']})\")\n","        else:\n","            print(f\"  Could not compute tau for {concept}\")\n","\n","    return results\n","\n","def run_full_analysis(single_response_mode=True):\n","    \"\"\"\n","    Run analysis for all models and cultural dimensions\n","\n","    Args:\n","        single_response_mode: Set to True when you have only 1 response per concept-identity pair\n","                             Set to False when you have multiple responses per concept-identity pair\n","    \"\"\"\n","\n","    # Cultural dimension files (you'll need to update these paths)\n","    cultural_configs = [\n","        {\n","            'name': 'Hofstede',\n","            'path': os.path.join(CULTURAL_VALUES_DIR, 'distances_hofstede_raw_with_demonymns.csv'),\n","            'type': 'hofstede_vector_distance'\n","        },\n","        {\n","            'name': 'World Values Survey',\n","            'path': os.path.join(CULTURAL_VALUES_DIR, 'wvs_250_dims_with_demonyms.csv'),\n","            'type': 'wvs_250_dims_vector_distance'\n","        }\n","    ]\n","\n","    all_results = {}\n","\n","    for config in cultural_configs:\n","        print(f\"\\n{'='*50}\")\n","        print(f\"ANALYZING WITH {config['name'].upper()}\")\n","        print(f\"{'='*50}\")\n","\n","        if not os.path.exists(config['path']):\n","            print(f\"Cultural values file not found: {config['path']}\")\n","            continue\n","\n","        all_results[config['name']] = {}\n","\n","        for model_file in MODEL_FILES:\n","            model_name = model_file.replace('responses_', '').replace('.jsonl', '')\n","\n","            try:\n","                results = analyze_model_correlations(\n","                    model_file,\n","                    config['path'],\n","                    config['type'],\n","                    'bertscore',  # Using BERTScore as you suggested\n","                    single_response_mode=single_response_mode\n","                )\n","                all_results[config['name']][model_name] = results\n","\n","            except Exception as e:\n","                print(f\"Error analyzing {model_file}: {str(e)}\")\n","                continue\n","\n","    return all_results\n","\n","def visualize_results(all_results):\n","    \"\"\"Create visualizations of the results\"\"\"\n","\n","    for cultural_dim in all_results:\n","        print(f\"\\n{cultural_dim} Results Summary:\")\n","        print(\"-\" * 40)\n","\n","        # Collect data for visualization\n","        models = []\n","        concepts = []\n","        taus = []\n","        p_values = []\n","\n","        for model in all_results[cultural_dim]:\n","            for concept in all_results[cultural_dim][model]:\n","                models.append(model)\n","                concepts.append(concept)\n","                taus.append(all_results[cultural_dim][model][concept]['tau'])\n","                p_values.append(all_results[cultural_dim][model][concept]['p_value'])\n","\n","        if not taus:\n","            print(\"No valid results to visualize\")\n","            continue\n","\n","        # Create DataFrame for easier plotting\n","        df = pd.DataFrame({\n","            'Model': models,\n","            'Concept': concepts,\n","            'Tau': taus,\n","            'P_Value': p_values\n","        })\n","\n","        # Print summary statistics\n","        print(f\"Mean Tau: {np.mean(taus):.4f}\")\n","        print(f\"Std Tau: {np.std(taus):.4f}\")\n","        print(f\"Significant correlations (p\u003c0.05): {sum(p \u003c 0.05 for p in p_values)}/{len(p_values)}\")\n","\n","        # Create heatmap\n","        if len(set(concepts)) \u003e 1 and len(set(models)) \u003e 1:\n","            pivot_df = df.pivot(index='Concept', columns='Model', values='Tau')\n","\n","            plt.figure(figsize=(12, 8))\n","            sns.heatmap(pivot_df, annot=True, cmap='RdBu_r', center=0,\n","                       fmt='.3f', cbar_kws={'label': \"Kendall's Tau\"})\n","            plt.title(f'Kendall\\'s Tau Correlations - {cultural_dim}')\n","            plt.tight_layout()\n","            plt.show()\n","\n","# Run the full analysis\n","print(\"Starting VLM Cultural Competence Analysis...\")\n","print(\"This will compute Kendall's tau correlations between text similarities and cultural distances\")\n","\n","# Set single_response_mode=True for current setup with 1 response per concept-identity pair\n","# Change to False once you have 5+ responses per prompt\n","SINGLE_RESPONSE_MODE = True\n","\n","print(f\"Running in {'single response' if SINGLE_RESPONSE_MODE else 'multiple response'} mode\")\n","\n","# Note: Make sure you have the cultural values CSV files in the right location\n","results = run_full_analysis(single_response_mode=SINGLE_RESPONSE_MODE)\n","\n","# Visualize results\n","visualize_results(results)\n","\n","# Print summary\n","print(\"\\n\" + \"=\"*60)\n","print(\"ANALYSIS COMPLETE\")\n","print(\"=\"*60)\n","\n","for cultural_dim in results:\n","    print(f\"\\n{cultural_dim} Summary:\")\n","    total_concepts = 0\n","    total_significant = 0\n","\n","    for model in results[cultural_dim]:\n","        concepts = len(results[cultural_dim][model])\n","        significant = sum(1 for c in results[cultural_dim][model]\n","                        if results[cultural_dim][model][c]['p_value'] \u003c 0.05)\n","        total_concepts += concepts\n","        total_significant += significant\n","\n","        print(f\"  {model}: {concepts} concepts, {significant} significant correlations\")\n","\n","    if total_concepts \u003e 0:\n","        print(f\"  Overall: {total_significant}/{total_concepts} significant correlations \"\n","                f\"({100*total_significant/total_concepts:.1f}%)\")\n","\n","print(f\"\\nNote: Running in {'single response' if SINGLE_RESPONSE_MODE else 'multiple response'} mode\")\n","if SINGLE_RESPONSE_MODE:\n","    print(\"Switch to SINGLE_RESPONSE_MODE = False once you have 5+ responses per prompt\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}